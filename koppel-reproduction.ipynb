{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This reproduction study prerequisites that you have obtained a copy of the [ETC Corpus of Non-Native and Written English](https://catalog.ldc.upenn.edu/LDC2014T06).\n",
    "Proceed to download and set up dependencies by running `pip3 install -r requirements.txt`.\n",
    "Then execute this notebook. If you want to use the `annotation` feature you need to download the annotations [from GitHub](https://github.com/Fohlen/toefl11-languagetool-annotations) and place them into the `responses/annotations` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/fohlen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/fohlen/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "TOEFL11_SCRIPT_PATH = 'toefl11.py'\n",
    "DATA_DIR = \"/home/fohlen/Documents/Bachelor/Data/ETS_Corpus_of_Non-Native_Written_English_LDC2014T06/ETS_Corpus_of_Non-Native_Written_English/data/text\"\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from nltk import download\n",
    "\n",
    "# NLTK downloads\n",
    "download('punkt')\n",
    "download('averaged_perceptron_tagger')\n",
    "\n",
    "# Download the onix stopwords corpus (http://www.lextek.com/manuals/onix/stopwords1.html)\n",
    "onix_path = os.path.join(os.getcwd(), 'onix.txt')\n",
    "if not os.path.exists(onix_path):\n",
    "    print(\"Downloading to \" + onix_path)\n",
    "    url = 'https://raw.githubusercontent.com/igorbrigadir/stopwords/master/en/onix.txt'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(onix_path, 'wb') as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets and vectorize test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration annotated-plain-text-0d2e219b700317ed\n",
      "Reusing dataset toef_l11 (/home/fohlen/.cache/huggingface/datasets/toef_l11/annotated-plain-text-0d2e219b700317ed/1.0.0/b9c961e4f11574a27d305d175682506a660414f7014938666c8b0848b288ed67)\n",
      "Using custom data configuration default-39065f4257a44a0b\n",
      "Reusing dataset text (/home/fohlen/.cache/huggingface/datasets/text/default-39065f4257a44a0b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
      "Using custom data configuration default-cedc0cd0a179dec0\n",
      "Reusing dataset text (/home/fohlen/.cache/huggingface/datasets/text/default-cedc0cd0a179dec0/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n"
     ]
    }
   ],
   "source": [
    "from KoppelVectorizer import KoppelVectorizer\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# The original experiment uses 129 essays for development where we use 5x the amount\n",
    "development = load_dataset(TOEFL11_SCRIPT_PATH,\n",
    "    data_dir=DATA_DIR,\n",
    "    split='train[:5%]',\n",
    "    name=\"annotated-plain-text\"\n",
    ")\n",
    "\n",
    "vectorizer = KoppelVectorizer(features=['stopwords', 'trigrams', 'bigrams', 'rare_pos_tags', 'annotation'])\n",
    "X_dev_train, X_dev_test, \\\n",
    "A_train, A_test, \\\n",
    "y_train, y_test = train_test_split(development[\"Text\"], development[\"Annotation\"], development[\"Language\"], test_size=0.33, random_state=42)\n",
    "labels = list(set(development[\"Language\"]))\n",
    "X_train = vectorizer.fit_transform(X_dev_train, A_train)\n",
    "y_train = np.array([labels.index(language) for language in y_train])\n",
    "X_test = vectorizer.transform(X_dev_test, A_test)\n",
    "y_test = np.array([labels.index(language) for language in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a multi-class linear SVM according to Koppel et al.\n",
    "Optionally one could try retraining for different feature sets (see KoppelVectorizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fohlen/Documents/Bachelor/koppel-reproduction/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fohlen/Documents/Bachelor/koppel-reproduction/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fohlen/Documents/Bachelor/koppel-reproduction/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'kernel': 'poly'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.261 (+/-0.093) for {'C': 100, 'kernel': 'rbf'}\n",
      "0.241 (+/-0.144) for {'C': 100, 'kernel': 'poly'}\n",
      "0.262 (+/-0.097) for {'C': 100, 'kernel': 'linear'}\n",
      "0.261 (+/-0.093) for {'C': 1000, 'kernel': 'rbf'}\n",
      "0.266 (+/-0.163) for {'C': 1000, 'kernel': 'poly'}\n",
      "0.262 (+/-0.097) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33        15\n",
      "           1       0.50      0.35      0.41        20\n",
      "           2       0.15      0.43      0.22         7\n",
      "           3       0.23      0.43      0.30        14\n",
      "           4       0.25      0.12      0.16        17\n",
      "           5       0.33      0.38      0.36        21\n",
      "           6       0.11      0.22      0.15         9\n",
      "           7       0.50      0.42      0.45        12\n",
      "           8       0.60      0.18      0.27        17\n",
      "           9       0.07      0.09      0.08        11\n",
      "          10       0.60      0.29      0.39        21\n",
      "\n",
      "    accuracy                           0.29       164\n",
      "   macro avg       0.33      0.29      0.28       164\n",
      "weighted avg       0.37      0.29      0.30       164\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.259 (+/-0.087) for {'C': 100, 'kernel': 'rbf'}\n",
      "0.249 (+/-0.108) for {'C': 100, 'kernel': 'poly'}\n",
      "0.268 (+/-0.063) for {'C': 100, 'kernel': 'linear'}\n",
      "0.259 (+/-0.087) for {'C': 1000, 'kernel': 'rbf'}\n",
      "0.246 (+/-0.120) for {'C': 1000, 'kernel': 'poly'}\n",
      "0.268 (+/-0.063) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.33      0.34        15\n",
      "           1       0.38      0.25      0.30        20\n",
      "           2       0.14      0.29      0.19         7\n",
      "           3       0.28      0.36      0.31        14\n",
      "           4       0.42      0.29      0.34        17\n",
      "           5       0.30      0.29      0.29        21\n",
      "           6       0.12      0.22      0.15         9\n",
      "           7       0.33      0.33      0.33        12\n",
      "           8       0.43      0.18      0.25        17\n",
      "           9       0.09      0.18      0.12        11\n",
      "          10       0.29      0.19      0.23        21\n",
      "\n",
      "    accuracy                           0.26       164\n",
      "   macro avg       0.28      0.26      0.26       164\n",
      "weighted avg       0.31      0.26      0.27       164\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tuned_parameters = [\n",
    "    {'kernel': ['rbf', 'poly', 'linear'], 'C': [100, 1000]},\n",
    "]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which features are contributing to the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('stopwords',)\n",
      "('trigrams',)\n",
      "('bigrams',)\n",
      "('rare_pos_tags',)\n",
      "('annotation',)\n",
      "('stopwords', 'trigrams')\n",
      "('stopwords', 'bigrams')\n",
      "('stopwords', 'rare_pos_tags')\n",
      "('stopwords', 'annotation')\n",
      "('trigrams', 'bigrams')\n",
      "('trigrams', 'rare_pos_tags')\n",
      "('trigrams', 'annotation')\n",
      "('bigrams', 'rare_pos_tags')\n",
      "('bigrams', 'annotation')\n",
      "('rare_pos_tags', 'annotation')\n",
      "('stopwords', 'trigrams', 'bigrams')\n",
      "('stopwords', 'trigrams', 'rare_pos_tags')\n",
      "('stopwords', 'trigrams', 'annotation')\n",
      "('stopwords', 'bigrams', 'rare_pos_tags')\n",
      "('stopwords', 'bigrams', 'annotation')\n",
      "('stopwords', 'rare_pos_tags', 'annotation')\n",
      "('trigrams', 'bigrams', 'rare_pos_tags')\n",
      "('trigrams', 'bigrams', 'annotation')\n",
      "('trigrams', 'rare_pos_tags', 'annotation')\n",
      "('bigrams', 'rare_pos_tags', 'annotation')\n",
      "('stopwords', 'trigrams', 'bigrams', 'rare_pos_tags')\n",
      "('stopwords', 'trigrams', 'bigrams', 'annotation')\n",
      "('stopwords', 'trigrams', 'rare_pos_tags', 'annotation')\n",
      "('stopwords', 'bigrams', 'rare_pos_tags', 'annotation')\n",
      "('trigrams', 'bigrams', 'rare_pos_tags', 'annotation')\n",
      "('stopwords', 'trigrams', 'bigrams', 'rare_pos_tags', 'annotation')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"\"\"\n",
    "    powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\n",
    "    \"\"\"\n",
    "    xs = list(iterable)\n",
    "    # note we return an iterator rather than a list\n",
    "    return chain.from_iterable(combinations(xs,n) for n in range(len(xs)+1))\n",
    "\n",
    "features = ['stopwords', 'trigrams', 'bigrams', 'rare_pos_tags', 'annotation']\n",
    "feature_combinations = list(powerset(features))[1:]\n",
    "feature_scores = []\n",
    "\n",
    "for combination in feature_combinations:\n",
    "    print(combination)\n",
    "    vectorizer.features = list(combination)\n",
    "    X_train, X_test = vectorizer.transform(X_dev_train, A_train), vectorizer.transform(X_dev_test, A_test)\n",
    "    clf = SVC(kernel='linear', C=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    feature_scores.append(accuracy_score(y_predict, y_test))\n",
    "\n",
    "def combination_to_str(combination):\n",
    "    return \",\".join([s[0] for s in combination])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,2])\n",
    "\n",
    "ax.bar([combination_to_str(combination) for combination in feature_combinations], feature_scores)\n",
    "plt.title(\"Feature importance\")\n",
    "plt.xlabel(\"s - stopwords; t - trigrams; b - bigrams; r - Rare POS tag; a - Annotations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 10 fold cross-validation as described in Koppel et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration plain-text-0d2e219b700317ed\n",
      "Reusing dataset toef_l11 (/home/fohlen/.cache/huggingface/datasets/toef_l11/plain-text-0d2e219b700317ed/1.0.0/b9c961e4f11574a27d305d175682506a660414f7014938666c8b0848b288ed67)\n",
      "Using custom data configuration plain-text-0d2e219b700317ed\n",
      "Reusing dataset toef_l11 (/home/fohlen/.cache/huggingface/datasets/toef_l11/plain-text-0d2e219b700317ed/1.0.0/b9c961e4f11574a27d305d175682506a660414f7014938666c8b0848b288ed67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636363636364\n",
      "0.4818181818181818\n",
      "0.4636363636363636\n",
      "0.509090909090909\n",
      "0.509090909090909\n",
      "0.5454545454545454\n",
      "0.5272727272727272\n",
      "0.5818181818181818\n",
      "0.5363636363636364\n"
     ]
    }
   ],
   "source": [
    "vals_ds = load_dataset(TOEFL11_SCRIPT_PATH,\n",
    "    data_dir=DATA_DIR,\n",
    "    split=[\n",
    "        f'validation[{k}%:{k+10}%]' for k in range(0, 100, 10)\n",
    "    ],\n",
    "    name=\"plain-text\"\n",
    ")\n",
    "trains_ds = load_dataset(TOEFL11_SCRIPT_PATH,\n",
    "    data_dir=DATA_DIR,\n",
    "    split=[\n",
    "        f'train[:{k}%]+train[{k+10}%:]' for k in range(0, 100, 10)\n",
    "    ],\n",
    "    name=\"plain-text\"\n",
    ")\n",
    "\n",
    "folding_scores = []\n",
    "max_model = None\n",
    "vectorizer.features = ['stopwords', 'trigrams', 'bigrams']\n",
    "\n",
    "for val_ds, train_ds in zip(vals_ds, trains_ds):\n",
    "    X_train, X_test = vectorizer.transform(train_ds[\"Text\"]), vectorizer.transform(val_ds[\"Text\"])\n",
    "    y_train, y_test = np.array([labels.index(language) for language in train_ds[\"Language\"]]), np.array([labels.index(language) for language in val_ds[\"Language\"]])\n",
    "    model = SVC(kernel='rbf', C=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_predict)\n",
    "    if score > max(folding_scores, default=0):\n",
    "        max_model = model\n",
    "    print(score)\n",
    "    folding_scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate feature matrix for optimum model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folding_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-06af2f2af9f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Maximum model accuracy: %s mean model accuracy: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolding_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolding_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'folding_scores' is not defined"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "print(\"Maximum model accuracy: %s mean model accuracy: %s\" % (max(folding_scores), mean(folding_scores)))\n",
    "print()\n",
    "y_pred = max_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "plot_confusion_matrix(max_model, X_test, y_test, display_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
